{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce9f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"../data_creation/plots_and_analysis\"))\n",
    "import config\n",
    "# adjust paths in /data_creation/plots_and_analysis/config.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3428c24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get accuracy metrics\n",
    "all_metrics_df = pd.read_parquet(f\"{config.path_to_evaluation}/results.parquet\")\n",
    "all_metrics_df[\"div_step\"] = all_metrics_df[\"div_step\"].astype(str)\n",
    "all_metrics_df.rename(columns={\"div_step\": \"div\", \"pot target size\": \"p\"}, inplace=True)\n",
    "all_metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0450a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append target features\n",
    "mean_target_features = pd.read_parquet(f\"{config.path_to_evaluation}/target_features_num.parquet\")\n",
    "all_metrics_df = all_metrics_df.merge(mean_target_features,on=[\"p\", \"div\", \"run\"], how=\"outer\")\n",
    "all_metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1357a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a0a214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load source features\n",
    "mean_source_features = pd.read_parquet(f\"{config.path_to_evaluation}/source_features_num.parquet\")\n",
    "mean_source_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bb4e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with source features\n",
    "# Merge the dataframes on 'div' and 'run' keys\n",
    "merged_df = all_metrics_df.merge(\n",
    "    mean_source_features, \n",
    "    on=['div', 'run'], \n",
    "    how='left', \n",
    "    suffixes=('', '_source')\n",
    ")\n",
    "\n",
    "# Fill missing values in rows where p='source'\n",
    "mask = merged_df['p'] == 'source'\n",
    "\n",
    "feature_columns = ['abs_energy', 'intermittency', \n",
    "                   'mean', 'median', 'kurtosis', 'skewness', 'standard_deviation', \n",
    "                   'agg_autocorrelation_max', 'erraticness', 'agg_linear_trend_slope']\n",
    "\n",
    "for col in feature_columns:\n",
    "    if f'{col}_source' in merged_df.columns:\n",
    "        merged_df.loc[mask, col] = merged_df.loc[mask, col].fillna(merged_df.loc[mask, f'{col}_source'])\n",
    "\n",
    "source_cols = [col for col in merged_df.columns if col.endswith('_source')]\n",
    "merged_df = merged_df.drop(columns=source_cols)\n",
    "\n",
    "all_metrics_df = merged_df\n",
    "all_metrics_df.rename(columns={\"agg_autocorrelation_max\":\"autocorr\", \"agg_linear_trend_slope\":\"trend\", \"standard_deviation\":\"sd\"}, inplace=True)\n",
    "all_metrics_df.to_parquet(f\"{config.path_to_evaluation}/results_metrics_features.parquet\")\n",
    "all_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cadb1b8",
   "metadata": {},
   "source": [
    "To avoid collinearity in the linear regression, calculate the Pearson correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85ec8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['abs_energy', 'intermittency', 'mean', 'median', 'kurtosis', \n",
    "                     'skewness', 'sd', 'autocorr', \n",
    "                     'erraticness', 'trend']\n",
    "\n",
    "div = \"aggregated\" #choose between: \"0\", \"5\", \"10\", \"aggregated\"\n",
    "\n",
    "if div == \"aggregated\":\n",
    "    complete_data = all_metrics_df[features].dropna() \n",
    "else:\n",
    "    complete_data = all_metrics_df.loc[all_metrics_df[\"div\"] == div][features].dropna()\n",
    "    \n",
    "correlation_matrix = complete_data.corr()\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'font.weight': 'bold',\n",
    "    'axes.labelweight': 'bold',\n",
    "    'axes.titleweight': 'bold',\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'xtick.major.width': 2,\n",
    "    'ytick.major.width': 2,\n",
    "    'axes.linewidth': 2\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, fmt='.2f', \n",
    "            annot_kws={'weight': 'bold', 'size': 10}) \n",
    "plt.tight_layout()  \n",
    "plt.savefig(f\"{config.path_to_evaluation}/feature_correlations_div{div}.pdf\",  bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda041c4",
   "metadata": {},
   "source": [
    "Choose feature sets with little collinearity and run a multiple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7894f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df[\"RMSSE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ea9524",
   "metadata": {},
   "outputs": [],
   "source": [
    "div = \"aggregated\" # choose between: \"0\", \"5\", \"10\", \"aggregated\"\n",
    "\n",
    "# chosen feature set\n",
    "features = ['autocorr', 'mean', 'skewness', 'trend']\n",
    "#['abs_energy','intermittency',  'trend',  'erraticness']\n",
    "#[ 'autocorr', 'mean', 'skewness', 'trend'] \n",
    "#['intermittency',  'mean',  'kurtosis', 'trend'] \n",
    "\n",
    "# Define targets\n",
    "targets = ['MASE', 'RMSSE', 'sMAPE']\n",
    "\n",
    "all_columns = features + targets\n",
    "if div == \"aggregated\":\n",
    "    complete_data = all_metrics_df[all_columns].dropna()\n",
    "else:\n",
    "    complete_data = all_metrics_df.loc[all_metrics_df[\"div\"] == div][all_columns].dropna()\n",
    "\n",
    "X = complete_data[features]\n",
    "X_with_const = sm.add_constant(X)\n",
    "\n",
    "# Create separate dictionaries to store results for each target\n",
    "results_dict = {}\n",
    "\n",
    "for target in targets:\n",
    "    y = complete_data[target]\n",
    "    \n",
    "    # Fit the model\n",
    "    model = sm.OLS(y, X_with_const).fit()\n",
    "    \n",
    "    # Store coefficients, p-values, and R2 for this target\n",
    "    results_dict[target] = {\n",
    "        'coefficients': model.params,\n",
    "        'pvalues': model.pvalues,\n",
    "        'r2': model.rsquared\n",
    "    }\n",
    "\n",
    "# Create the final DataFrame with desired structure\n",
    "feature_names = ['const'] + features\n",
    "\n",
    "# Create columns with R2 in parentheses next to target names\n",
    "columns = [('Feature', '')]\n",
    "for target in targets:\n",
    "    r2_formatted = f\"{target} (R2={results_dict[target]['r2']:.2f})\"\n",
    "    columns.extend([\n",
    "        (r2_formatted, 'Coefficient'),\n",
    "        (r2_formatted, 'P-value')\n",
    "    ])\n",
    "\n",
    "multi_columns = pd.MultiIndex.from_tuples(columns)\n",
    "\n",
    "data_rows = []\n",
    "for feature in feature_names:\n",
    "    row_data = [feature] \n",
    "    for target in targets:\n",
    "        row_data.extend([\n",
    "            round(results_dict[target]['coefficients'][feature], 2),\n",
    "            round(results_dict[target]['pvalues'][feature], 4)\n",
    "        ])\n",
    "    data_rows.append(row_data)\n",
    "\n",
    "\n",
    "final_df = pd.DataFrame(data_rows, columns=multi_columns)\n",
    "\n",
    "print(\"Results Summary:\")\n",
    "print(final_df)\n",
    "\n",
    "final_df.to_csv(f\"{config.path_to_evaluation}/ols_{features}_all_metrics_div{div}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b956fc",
   "metadata": {},
   "source": [
    "Plot the erraticness against the RMSSE and MASE and the intermittency against the sMAPE. Fit a linear line and calculate the slope and p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a398e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "df = all_metrics_df\n",
    "\n",
    "unique_pot_target_sizes = df[\"p\"].unique()\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, len(unique_pot_target_sizes)))\n",
    "\n",
    "def plot_linear_fit(ax, x, y, metric):\n",
    "    if len(x) > 1:\n",
    "        # Linear regression\n",
    "        linear_coeffs = np.polyfit(x, y, deg=1)\n",
    "        linear_eq = np.poly1d(linear_coeffs)\n",
    "        x_fit = np.linspace(min(x), max(x), 100)\n",
    "        y_fit = linear_eq(x_fit)\n",
    "        \n",
    "        ax.plot(x_fit, y_fit, linestyle=\"--\", alpha=0.9, linewidth=5, color='black')\n",
    "        \n",
    "        scatter_plots = []\n",
    "        for i, size in enumerate(unique_pot_target_sizes):\n",
    "            mask = df[\"p\"] == size\n",
    "            scatter_plot = ax.scatter(x[mask], y[mask], c=[colors[i]], s=250, edgecolors=\"w\", alpha=0.9, linewidth=2)\n",
    "            scatter_plots.append(scatter_plot)\n",
    "\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "\n",
    "        if metric == 'sMAPE':\n",
    "            ax.annotate(f\"Slope: {slope:.3f}\\np-value: {p_value:.3e}\",\n",
    "                        xy=(0.05, 0.95), xycoords='axes fraction', fontsize=18,\n",
    "                        ha='left', va='top',\n",
    "                        bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor='black', facecolor='lightgray'))\n",
    "        elif metric in ['RMSSE', 'MASE']:\n",
    "            ax.annotate(f\"Slope: {slope:.3f}\\np-value: {p_value:.3e}\",\n",
    "                        xy=(0.95, 0.95), xycoords='axes fraction', fontsize=18,\n",
    "                        ha='right', va='top',\n",
    "                        bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor='black', facecolor='lightgray'))\n",
    "        \n",
    "        return scatter_plots[0]  \n",
    "\n",
    "# Intermittency vs. sMAPE\n",
    "scatter1 = plot_linear_fit(axes[0], df[\"intermittency\"], df[\"sMAPE\"], \"sMAPE\")\n",
    "axes[0].set_xlabel(\"Intermittency\", fontsize=24)\n",
    "axes[0].set_ylabel(\"sMAPE\", fontsize=24)\n",
    "axes[0].set_title(\"Intermittency vs. sMAPE\", fontsize=24)\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Erraticness vs. RMSSE\n",
    "scatter2 = plot_linear_fit(axes[1], df[\"erraticness\"], df[\"RMSSE\"], \"RMSSE\")\n",
    "axes[1].set_xlabel(\"Erraticness\", fontsize=24)\n",
    "axes[1].set_ylabel(\"RMSSE\", fontsize=24)\n",
    "axes[1].set_title(\"Erraticness vs. RMSSE\", fontsize=24)\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Erraticness vs. MASE\n",
    "scatter3 = plot_linear_fit(axes[2], df[\"erraticness\"], df[\"MASE\"], \"MASE\")\n",
    "axes[2].set_xlabel(\"Erraticness\", fontsize=24)\n",
    "axes[2].set_ylabel(\"MASE\", fontsize=24)\n",
    "axes[2].set_title(\"Erraticness vs. MASE\", fontsize=24)\n",
    "axes[2].grid(True)\n",
    "\n",
    "\n",
    "legend_elements = []\n",
    "for i, size in enumerate(unique_pot_target_sizes):\n",
    "    legend_elements.append(plt.Line2D([0], [0], marker='o', color='w', \n",
    "                                    markerfacecolor=colors[i], markersize=12, \n",
    "                                    markeredgecolor='white', markeredgewidth=0.5, \n",
    "                                    label=size))\n",
    "\n",
    "fig.legend(title=\"Potential Target Size\", handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, 0.02), \n",
    "          ncol=len(unique_pot_target_sizes), fontsize=18, frameon=True, title_fontsize=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.2) \n",
    "plt.savefig(f\"{config.path_to_evaluation}/single_ols_erraticness_intermittency.pdf\",  bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main-env-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
